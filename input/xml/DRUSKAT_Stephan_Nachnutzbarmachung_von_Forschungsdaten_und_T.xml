<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>
                    <title>Nachnutzbarmachung von Forschungsdaten und Tools am Beispiel altäthiopischer Korpora</title>
                    <title/>
                </title>
                <author>
                    <persName>
                        <surname>Druskat</surname>
                        <forename>Stephan</forename>
                    </persName>
                    <affiliation>Humboldt-Universität zu Berlin, Deutschland</affiliation>
                    <email>stephan.druskat@hu-berlin.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Vertan</surname>
                        <forename>Cristina</forename>
                    </persName>
                    <affiliation>Universität Hamburg, Deutschland</affiliation>
                    <email>fsha060@uni-hamburg.de</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2017-09-25T22:48:51.500556008</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Prof. Dr. Georg Vogeler</publisher>
                <address>
                    <addrLine>UniversitÃ¤t Graz</addrLine>
                    <addrLine>Zentrum fÃ¼r Informationsmodellierung - Austrian Centre for Digital Humanities</addrLine>
                    <addrLine>ElisabethstraÃ&#x9f;e 59/III</addrLine>
                    <addrLine>8010 Graz</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from an OASIS Open Document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application>
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords>
                    <term>Paper</term>
                </keywords>
                <keywords>
                    <term>Vortrag</term>
                </keywords>
                <keywords>
                    <term>Nachnutzung</term>
                    <term>Datenformate</term>
                    <term>Nachhaltigkeit</term>
                    <term>Forschungssoftware</term>
                </keywords>
                <keywords>
                    <term>Programmierung</term>
                    <term>Annotieren</term>
                    <term>Visualisierung</term>
                    <term>Daten</term>
                    <term>Interaktion</term>
                    <term>Software</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <div>
                <head>Einleitung</head>
                <p>In den letzten Jahren wurden verschiedene Werkzeuge zur Annotation von Dokumenten entwickelt, z.B. 
                    <hi>WebAnno</hi> (Eckart de Castilho et al. 2016), 
                    <hi>Cor</hi>
                    <hi>A</hi> (Bollmann et al. 2014) und 
                    <hi>CATMA</hi> (Meister et al. 2016). Diese Werkzeuge bieten zahlreiche Funktionalitäten, die für viele Sprachen und Anwendungen ausreichend sind. Die Unterstützung verschiedener Skripten erweckt den Eindruck, dass diese Werkzeuge für die Annotation aller Sprachkorpora erfolgreich eingesetzt werden können, was solange korrekt ist, wie man sehr flache Annotation durchführt.
                </p>
                <p>Tiefere Annotationen, insbesondere für Sprachen außerhalb der Europäischen Sprachfamilie oder für historische Sprachen, dagegen gestalten sich problematischer. Häufig jedoch wird die Verwendung bereits etablierter Annotationstools trotzdem bevorzugt, weil diese eine reibungslose Integration mit weiteren Analyse- und Visualisierungs-Tools wie z.B. 
                    <hi>ANNIS</hi> (Krause &amp; Zeldes 2016) versprechen. In diesem Beitrag werden wir zeigen, dass die Entwicklung dedizierter Annotationswerkzeuge dann als Lösung in Betracht gezogen werden kann, wenn gleichzeitig Schnittstellen (z.B. zu Analyse-Tools) entwickelt werden, die die Neuentwicklung wiederum an vorhandene Software und Infrastrukturen anbinden. Auf diese Weise können die Nachteile einer Neuentwicklung unter Gesichtspunkten der nachhaltigen Entwicklung von Forschungssoftware gegenüber der Anpassung bestehender Tools - bei gleichzeitiger Ermöglichung eines spezialisierten Anwendungsfalles - weitgehend abgeschwächt werden. Der Vorteil eines solchen Verfahrens ist die Realisierung eines Annotationsmodells, das exakt den Besonderheiten der Sprache entspricht. 
                    <anchor/>Insbesondere für diachrone Analysen ist es häufig nötig, dass man eine sehr detaillierte Modellierung der morphologischen, syntaktischen und semantischen Merkmale vornimmt, da die Unterschiede häufig nur im Detail reflektiert sind.
                    <hi> </hi>Im Einzelnen werden wir die Entwicklung des 
                    <hi>GeTa</hi>-Annotationstools, eines Mehrebenenannotationswerkzeugs für die Altäthiopische Sprache, und dessen Integration mit dem Such- und Visualisierungsframework 
                    <hi>ANNIS</hi> darstellen.
                </p>
            </div>
            <div>
                <head>Spezielle Anforderungen für die Altäthiopische Sprache</head>
                <p>Das Altäthiopische (Geʿez), ist eine südsemitische Sprache. Es war bis ins 19. Jahrhundert hinein die bedeutendste Schriftsprache des christlichen Äthiopien. Die reiche christlich-äthiopische Literatur ist zunächst von Übersetzungen - anfangs aus dem Griechischen und später aus dem Arabischen - geprägt, bevor sich eine mannigfaltige indigene Literatur mit ganz eigenen Zügen entwickelt. Insbesondere Texte, die einzig im Altäthiopischen vollständig überliefert, und deren Textzeugen in anderen Sprachen entweder vollständig verloren, oder von denen nur Fragmente erhalten sind (z.B. das Henochbuch) erlangen dabei ganz besondere Bedeutung (Vertan et. al. 2016).</p>
                <p>Das Altäthiopische hat aus einer südsemitischen Schrift ein eigenes Silbenalphabet entwickelt, das bis heute in mehreren modernen Sprachen Äthiopiens und Eritreas Verwendung findet. Innerhalb der semitischen Sprachen fällt es durch die verwendete Rechtsläufigkeit auf; außerdem werden die Vokale vollständig geschrieben. Das äthiopische Silbenalphabet bringt dabei mit sich, dass Morphemgrenzen in der Schrift nicht darstellbar sind, sodass beispielsweise ein einzelner Vokal als Bestandteil einer Silbe eine eigenständige Wortart darstellen kann und tokenisiert werden muss; z.B. ist im zweisilbigen Wort ቤቱ፡ /be·tu/ das /u/ als pronominales Suffix zu bet-
                    <hi>u</hi> (
                    <hi>sein</hi> Haus) zu segmentieren. Eine solche Annotation kann nur auf der Transkription erfolgen. Annotationen auf anderen Ebenen (z.B. Seiten- Spaltenumbrüche, Textkorrekturen) müssen auf dem Fidal-Skript realisiert werden. Dies bedeutet, dass Original und Transkription synchronisiert im Annotationswerkzeug dargestellt werden müssen. Eine korrekte Darstellung einer Transliteration benötigt die Transkription. Während diese regelbasiert automatisch durchgeführt werden kann, ist korrekte Transliteration (z.B. Konsonantendopplung) in vielen Fällen nur zusammen mit morphologischer Analyse möglich. Daher muss das Annotationstool Korrekturen am Basistext während der Annotation zulassen und zuverlässig verarbeiten können. Keins der existierenden Annotationswerkzeuge erfüllt diese Voraussetzungen. CorA arbeitet mit Listen von Wertkombinationen von Attributen. Die benötigte morphologische Annotation im Fall der altäthiopischen Sprache umfasst 30 Merkmale, mit je mindestens drei möglichen Werten. Die Handhabung solch einer umfangreichen Liste macht manuelle Annotation praktisch unmöglich. Weder WebAnno noch CATMA ermöglichen die Korrektur des zugrunde liegenden Textes während der Annotation. Die Implementierung einer solchen Funktion auf Basis eines dieser Werkzeuge würde tief in die Architektur der Software eingreifen, was innerhalb der Laufzeit des Projektes nicht realisierbar war. Auch die semi-automatischen Annotationsmöglichkeiten unter Supervision des Benutzenden sind für diese beiden Werkzeuge nicht leicht erweiterbar.
                </p>
            </div>
            <div>
                <head>Das GeTa Annotationstool</head>
                <p>Im TraCES-Projekt
                    <note>
                        <ptr/>.
                    </note>, das als Hauptziel die Entwicklung eines diachronen, tief annotierten Korpus für die Altäthiopische Sprache hat, implementieren wir eine neuartige Architektur, die sowohl Änderungen im Text als auch eine Mehrebenenannotation ermöglicht.
                </p>
                <p>Wir betrachten als Grundtext den Originaltext in der altäthiopischen Schrift. Die Transliteration bildet die erste, die morphologische Annotation die zweite Ebene, wobei die Transliteration und der Originaltext bei allen Arbeitsschritten synchronisiert bleiben. Im folgenden Abschnitt beschreiben wir das Datenmodell, das diese Architektur ermöglicht.</p>
                <p>Die Basiseinheit in unserem System ist ein Wort, das eine einmalige ID zugewiesen erhält (graphische Einheit). Ein Wort hat folgende Komponenten:</p>
                <list>
                    <item>Eine Liste der einzelnen Fidal
                        <note> "Fidal" ist der Terminus technicus für das äthiopische Silbenalphabet.</note>-Objekte, wobei ein Fidal-Objekt aus einer ID und einem Label (dem Fidal-Buchstaben) besteht.
                    </item>
                    <item>Eine Liste einzelner Silben-Objekte, wobei ein Silben-Objekt aus einer ID und einer Liste von einzelnen Buchstaben-Objekten besteht.</item>
                    <item>Ein Buchstaben-Objekt hat immer eine ID und ein Label (das graphische Symbol).</item>
                </list>
                <p>Graphische Einheiten können in mehreren Tokens geteilt werden. Die Tokens sind getrennt gespeichert (mit eigenenen IDs) und verlinkt mit der graphischen Einheit. Elemente der Textstruktur werden durch selbständige Objekte dargestellt, die mit den beinhalteten Tokens verlinkt werden. Editorische Annotationen werden mit den graphischen Einheiten verlinkt. Eine derartig stark vernetzte komplexe Struktur ist mit XML schwierig zu modellieren, insbesondere bei manueller Annotation. Auch die maschinelle Verarbeitung einer derartig tief vernetzten TEI-Struktur wäre sehr kompliziert. Alternativ bietet JSON für dieses Modell eine bessere Handhabbarkeit. Wir haben uns daher entschieden, die Daten in JSON zu speichern und zusätzlich XML-Export zu implementieren. Die Datenstruktur ist in vier JSON-Dateien gespeichert: eine für die graphischen Einheiten, eine für die Tokens, je eine für weitere Annotationsebenen (Textstruktur und Edition). Diese JSON-Dateisammlung wird via Konverterschnittstelle nach 
                    <hi>ANNIS</hi> importiert.
                </p>
            </div>
            <div>
                <head>corpus-tools.org: 
                    <hi>ANNIS</hi>, 
                    <hi>Pepper</hi>, 
                    <hi>Salt</hi>
                </head>
                <p>
                    <hi>ANNIS</hi> (Krause &amp; Zeldes 2016) ist eine Such- und Visualisierungsplattform für linguistische Daten, die mehrebenenfähig ist, d.h., verschiedene Annotationsebenen eines Korpus darstellen kann und dabei verschiedenste Annotationsarten berücksichtigt. Dies macht 
                    <hi>ANNIS</hi> zu einem hervorragenden Analysetool für die Daten des TraCES-Projekts. Eine besondere Rolle dabei spielt die Mächtigkeit der 
                    <hi>ANNIS</hi>-eigenen Abfragesprache AQL (ANNIS Query Language), die neben Freitextsuche und regulären Ausdrücken sich vor allem dadurch auszeichnet, linguistische Strukturen über mehrere Ebenen suchen zu können.
                </p>
                <p>Durch 
                    <hi>ANNIS</hi>‘ beschriebene Eigenschaften und seine Konfigurierbarkeit ist die Software für die Verwendung in den unterschiedlichsten Analyseszenarien geeignet und wird in der Tat bereits in verschiedenen Communities verwendet, z.B. in historischer Linguistik, Typologie, Sprachdokumentation u.v.m.
                </p>
                <p>Diese Eignung wird verstärkt durch eine hohe Kompatibilität mit vielen unterschiedlichen linguistischen Datenformaten, die erreicht wird durch Einsatz von 
                    <hi>Pepper</hi> (Zipser et al. 2011), einem Konvertierungsframework für liguistische Daten. 
                    <hi>Pepper</hi> nutzt ein generisches, graphbasiertes Zwischenmodell, 
                    <hi>Salt</hi> (Zipser &amp; Romary 2010), das unterschiedlichste, auch über mehrere Ebenen eines Korpus verteilte, Annotationsarten aufnehmen kann und so weiterverarbeitbar macht. 
                    <hi>Pepper</hi> zeichnet sich weiterhin durch eine Plugin-Architektur aus, die es ermöglicht mit geringem Aufwand sowohl Import- als auch Manipulations- und Exportmodule zu entwickeln, die die Quelldaten in ein 
                    <hi>Salt</hi>-Modell im Hauptspeicher übertragen, das dort manipuliert werden und anschließend in ein Zielformat überführt werden kann.
                </p>
                <p>
                    <hi>ANNIS</hi>, 
                    <hi>Pepper</hi> und 
                    <hi>Salt</hi> sind Komponenten der Softwarefamilie 
                    <hi>corpus-tools.org</hi> (Druskat et al. 2016).
                </p>
            </div>
            <div>
                <head>Schnittstelle zwischen 
                    <hi>GeTa</hi> und 
                    <hi>ANNIS</hi>
                </head>
                <p>Diese Infrastruktur ermöglicht es ohne Weiteres, die in 
                    <hi>GeTa</hi> annotierten Daten über ein dediziertes 
                    <hi>GeTa</hi>-Importmodul für 
                    <hi>Pepper</hi> und die Verwendung der bereits existierenden 
                    <hi>ANNIS</hi>-Module für 
                    <hi>Pepper</hi> – hier das Exportmodul – in 
                    <hi>ANNIS</hi> verarbeitbar zu machen. Mit 
                    <hi>GeTaModules </hi>(Druskat 2018) haben wir einen solchen Importer entwickelt, dessen Funktionsweise hier kurz beschrieben werden soll. 
                    <hi>GeTaModules</hi> ist in Java implementiert und wird als OSGi-Bundle ausgeliefert, das von 
                    <hi>Pepper</hi>s OSGi-Plattform verwaltet werden kann. 
                    <hi>GeTaModules</hi> ist Open Source unter der Apache License, Version 2.0.
                </p>
                <p>Um Performanz und Speicherökonomie zu optimieren nutzt der 
                    <hi>GeTaModules</hi>-Importer eine Kombination aus Streaming und Object-Mapping-Methoden, um die aus 
                    <hi>GeTa</hi> exportierten JSON-Dateien einzulesen. Dabei werden die kleinsten Einheiten der Transliteration auf den graphischen Einheiten genutzt, um eine Tokenisierung in 
                    <hi>Salt</hi> zu erstellen und einen virtuellen Primärtext aufzubauen. Auf den so erstellten Modelltokens werden rekursiv die Silben- und Fidal-Objekte als Spannen aufgebaut. Im Anschluss werden die linguistischen Annotationen der 
                    <hi>GeTa</hi>-Tokens sowie die weiteren Annotationen aus den JSON-Objekten per Identifikator auf die entsprechenden Einheiten projiziert.
                </p>
                <p>In diesem Zustand hält 
                    <hi>Pepper</hi> einen kompletten 
                    <hi>Salt</hi>-Dokumentgraphen für das entsprechende Korpusdokument im Hauptspeicher. In einem weiteren Schritt werden Ordnungsrelationen jeweils zwischen den Knoten der Fidal und der transliterierten Wortebene erstellt, damit diese später in 
                    <hi>ANNIS</hi> als Segmentierungsgrundlage angezeigt werden können.
                </p>
                <p>Im dritten Schritt werden mit Hilfe des 
                    <hi>ANNIS</hi>-Exportmoduls
                    <note>
                        <ptr/>.
                    </note> die für den Import in 
                    <hi>ANNIS </hi>benötigten Dateien im nativen Format geschrieben. Diese können nun in 
                    <hi>ANNIS</hi> über dessen graphische Benutzeroberfläche importiert werden.
                </p>
                <p>Die Konfiguration der Visualisierungen erfolgt durch Anpassung einer während des Exportvorgangs generierten Konfigurationsdatei. Im Fall der 
                    <hi>GeTa</hi>-Daten müssen hier lediglich die anzuzeigenden Annotationsebenen und ihre Reihenfolge eingestellt werden. In den 
                    <hi>ANNIS</hi>-Daten wird weiterhin ein dedizierter HTML-Visualisierer konfiguriert, der Wortartenannotationen auch graphisch Fidalwörtern zuordnet.
                </p>
                <p>Mit 
                    <hi>Pepper</hi> erfolgt die Konvertierung auf der Kommandozeile und die Konfiguration in Textdateien. Da dies für einige potenzielle Anwendergruppen unbekanntes Terrain bedeuten könnte haben wir den Prototypen einer Desktopanwendung für 
                    <hi>Pepper</hi> für die Verwendung mit 
                    <hi>GeTaModules</hi> angepasst, die eine grafische Oberfläche für die Verwendung von 
                    <hi>Pepper</hi> bietet: 
                    <hi>Pepper Grinder</hi> (Druskat 2017). 
                    <hi>Pepper Grinder (TraCES Edition)</hi> bietet so den Workflow für die Konvertierung der 
                    <hi>GeTa</hi>-Daten nach 
                    <hi>ANNIS</hi> quasi per Knopfdruck an. 
                    <hi>Pepper Grinder</hi> wird in Zukunft in eine vollfunktionale Anwendung ausgebaut, die Modi für verschiedene Anwendergruppen anbieten wird.
                </p>
                <p>Neben der projektinternen Nutzung von 
                    <hi>GeTaModules</hi> für die Konvertierung in das 
                    <hi>ANNIS</hi>-Format eröffnet die Software weitere Nachnutzungsszenarien für die annotierten Daten. Durch die Existenz von Manipulator- und Export-Modulen für 
                    <hi>Pepper</hi> für die verschiedensten Datenformate können die Daten mit anderen Werkzeugen nachgenutzt und etwa um zusätzliche Annotationsebenen angereichert, oder mit anderen Visualisierungen zu weiteren Forschungsfragen analysiert werden. 
                    <anchor/>Gleichzeitig leistet die Nachnutzung und Anpassung von 
                    <hi>Pepper</hi> durch 
                    <hi>GeTaModules</hi> einen Beitrag zur Vernachhaltigung dieses Frameworks. Durch die Ermöglichung des Imports von GeTa-Daten in ANNIS wird aus dem GeTa-Modell eine durchaus attraktive Modellierungsalternative für andere Sprachen mit ähnlichen Merkmalen. Derzeit wird das Modell in laufenden Projekten zu Mayasprachen und Jiddisch erprobt.
                </p>
                <p>Zusammenfassend stellt unser Ansatz eine Alternative dar zu Tendenzen der „Format-Hoheit“, also der Modellierung auf Grundlage eines – eventuell de facto standardisierten – Datenformats im Gegensatz zur Modellierung auf Grundlage der Forschungsfrage und der vorliegenden Daten. Die Einrichtung von Schnittstellen, wie z.B. 
                    <hi>GeTaModules</hi>, die eine Nachnutzbarkeit der Daten auch über die ursprüngliche Erstellung hinaus gewährleisten können, ermöglicht eine optimierte Modellierung und die Entwicklung spezifischer, den Bedürfnissen der Forschung und ihrer Daten hochgradig angepasster Werkzeuge, wie etwa 
                    <hi>GeTa</hi>.
                </p>
            </div>
        </body>
        <back>
            <div>
                <listBibl>
                    <head>Bibliographie</head>
                    <bibl>
                        <hi>Bollmann, </hi>
                        <hi>Marcel / </hi>
                        <hi>Petran, Florian / Dipper, Stefanie / Krasselt, </hi>
                        <hi>Julia</hi>
                        <hi> </hi>(2014): „
                        <emph>CorA: A web-based annotation tool for historical and other non-standard language data“, </emph>
                        <emph>i</emph>n: 
                        <hi>Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH)</hi>. Gothenburg, Sweden: 86-90.
                    </bibl>
                    <bibl>
                        <hi>Druskat, Stephan</hi> (2018): „GeTaModules (Version 0.9.0)“. Zenodo. DOI: 10.5281/zenodo.1146985. 
                        <ptr/>
                    </bibl>
                    <bibl>
                        <hi>Druskat, </hi>
                        <hi>Stephan</hi> (2017): „Pepper Grinder (Version 0.1.7)“. Zenodo. DOI: 10.5281/zenodo.1041735. 
                        <ptr/>
                    </bibl>
                    <bibl>
                        <hi>Druskat, Stephan / Gast, Volker / Krause, Thomas / Zipser, Florian </hi>(2016): "corpus-tools.org: An Interoperable Generic Software Tool Set for Multi-layer Linguistic Corpora", in: 
                        <hi>Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016):</hi> 23–28.
                    </bibl>
                    <bibl>
                        <hi>Eckart de Castilho, R</hi>
                        <hi>ichard / </hi>
                        <hi>Mújdricza-Maydt, É</hi>
                        <hi>va /</hi>
                        <hi> Yimam, S</hi>
                        <hi>eid Muhie /</hi>
                        <hi> Hartmann, S</hi>
                        <hi>ilvana / </hi>
                        <hi>Gurevych, I</hi>
                        <hi>ryna /</hi>
                        <hi> Frank, A</hi>
                        <hi>nette / </hi>
                        <hi>Biemann, C</hi>
                        <hi>hris</hi> (2016): „A Web-based Tool for the Integrated Annotation of Semantic and Syntactic Structures“, in: 
                        <hi>Proceedings of the LT4DH workshop at COLING 2016, Osaka, Japan: </hi>76-84.
                    </bibl>
                    <bibl>
                        <hi>Krause, Thomas / Zeldes, Amir </hi>(2016): "ANNIS3: A new architecture for generic corpus query and visualization", in: 
                        <hi>Digital Scholarship in the Humanities</hi>: 118-139.
                    </bibl>
                    <bibl>
                        <hi>Meister, J.C. / Petris, M. / Gius, E. / Jacke, J.</hi> (2016): CATMA 5.0 [Software for text annotation and analysis] 
                        <ref>http://www.catma.de</ref> [letzter Zugriff 10.01.2018]
                    </bibl>
                    <bibl>
                        <hi>Vertan, Cristina / Ellwardt, Andreas / Hummel, Susanne </hi>(2016): "Ein Mehrebenen-Tagging-Modell für die Annotation altäthiopischer Texte", in: 
                        <hi>Proceedings der DHd-Konferenz 2016</hi>
                        <ref>http://www.dhd2016.de/abstracts/vortr%C3%A4ge-061.html</ref> [letzter Zugriff 25.09.2017].
                    </bibl>
                    <bibl>
                        <hi>Zipser, Florian / Romary, Laurent </hi>(2010): "A model oriented approach to the mapping of annotation formats using standards", in: 
                        <hi>Proceedings of the Workshop on Language Resource and Language Technology Standards (LREC 2010)</hi>
                        <ptr/> [letzter Zugriff 25.09.2017].
                    </bibl>
                    <bibl>
                        <hi>Zipser, Florian / Zeldes, Amir / Ritz, Julia / Romary, Laurent / Leser, Ulf</hi> (2011): "Pepper: Handling a multiverse of formats", Poster, 
                        <hi>33. Jahrestagung der Deutschen Gesellschaft für Sprachwissenschaft</hi>, Göttingen.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
