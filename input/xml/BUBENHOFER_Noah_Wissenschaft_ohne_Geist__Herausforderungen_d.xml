<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0"
     xml:id="BUBENHOFER_Noah_Wissenschaft_ohne_Geist__Herausforderungen_d">
   <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Wissenschaft ohne Geist: Herausforderungen der Digital Humanities am Beispiel der Korpuslinguistik</title>
                <author>
                    <persName>
                        <surname>Bubenhofer</surname>
                        <forename>Noah</forename>
                    </persName>
                    <affiliation>Universität Zürich, Schweiz</affiliation>
                    <email>bubenhofer@cl.uzh.ch</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2015-10-04T22:02:00Z</date>
                </edition>
            </editionStmt>
            <publicationStmt>
            <t:publisher xmlns:t="http://www.tei-c.org/ns/1.0">Georg Vogeler, im Auftrag des Verbands Digital Humanities im deutschaprachigen Raum e.V.</t:publisher>
            <t:address xmlns:t="http://www.tei-c.org/ns/1.0">
               <t:addrLine>Universität Graz</t:addrLine>
               <t:addrLine>Zentrum für Informationsmodellierung - Austrian Centre for Digital Humanities</t:addrLine>
               <t:addrLine>Elisabethstraße 59/III</t:addrLine>
               <t:addrLine>8010 Graz</t:addrLine>
            </t:address>
         </publicationStmt>
            <sourceDesc>
                <p>Converted from a Word document </p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.17">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Vortrag</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>Korpuslinguistik</term>
                    <term>Computerlinguistik</term>
                    <term>Deep Learning</term>
                    <term>Textmining</term>
                    <term>Geistewissenschaften</term>
                </keywords>
                <keywords scheme="ConfTool" n="topics">
                    <term>Modellierung</term>
                    <term>Theoretisierung</term>
                    <term>Methoden</term>
                    <term>Forschungsprozess</term>
                </keywords>
            </textClass>
        <settingDesc>
            <ab n="conference">DHd2018 - "Kritik der Digitalen Vernunft", Köln</ab>
            <ab n="paperID">288</ab>
            <ab n="session_ID">32</ab>
            <ab n="session_numberInSession">3</ab>
            <ab n="session_short">VP_2a</ab>
            <ab n="session_title">Theorie der digitalen Geisteswissenschaften II</ab>
            <ab n="session_start">2018-02-28 11:00</ab>
            <ab n="session_end">2018-02-28 12:30</ab>
         </settingDesc>
      </profileDesc>
    </teiHeader>
   <text>
        <body>
            <p>Alle, die mit maschinellen Methoden Sprache analysieren, erleben momentan einen tiefgreifenden methodologischen Wandel.<ref target="ftn1" n="1"/> 
                Einerseits erfreut man sich vielleicht als Geisteswissenschaftler/in am immer stärkeren Interesse der Ingenieurtechniken und der Informatik für Sprache. Dies kann durchaus als Erfolg der Linguistik betrachtet werden, zurückgehend auf den Linguistic Turn, der viele andere Disziplinen schon seit Jahrzehnten beeinflusst. Unternehmen interessieren sich für ihre Reputation im massenmedialen Diskurs oder sind der Überzeugung, ihr in unzähligen Dokumenten versprachlichtes Wissen besser verwalten zu können, wenn sie es nach sprachlichen Kriterien neu ordnen. Das Geschäftsmodell von Internetunternehmen basiert ganz erheblich darauf, sprachliche Kommunikation maschinell zu verarbeiten um daraus Wissen aufzubauen und Vorhersagen über das Handeln von Kunden zu machen. Auch in der Politik ist die Analyse von Sprachgebrauch ein wichtiger Faktor, um Wahlkämpfe zu gewinnen.
            </p>
            <p>Andererseits beschert einen dieses Interesse eine Vielzahl von neuen Methoden für die maschinelle Analyse von Text, die auch für geisteswissenschaftliche Fragestellungen interessant sind. Die Digital Humanities sind ein Beispiel für eine Disziplin, die sich den Experimenten mit diesen Methoden verschrieben hat. Auch die Korpuslinguistik profitiert maßgeblich von diesen neuen Methoden.</p>
            <p>Aktuell erfahren in der Computerlinguistik und generell im Data Mining neuronale Netze großen Zuspruch, die den Prozess des maschinellen Lernens nach dem Modell des menschlichen Gehirns gestalten. Solche Systeme, „Deep Learning“-Systeme genannt, sind in der Lage, Muster in den Daten zu erkennen, ohne dass vorher explizit die Eigenschaften festgelegt werden, die getestet werden sollen. Zudem findet das Lernen auf mehreren verborgenen Ebenen statt, so dass das Lernen nicht beobachtet und damit auch die Frage, welche Eigenschaften nun welchen Einfluss auf das gelernte Modell haben, kaum beantwortet werden kann.</p>
            <p>In der Computerlinguistik wurden bereits für viele Probleme Deep-Learning-Algorithmen eingesetzt, meist mit Erfolg. Erfolg bedeutet, dass die statistischen Modelle besser den Goldstandard voraussagen können, aber nicht, dass das grundlegende linguistische Problem (z.B.: Sentiment-Analyse: wie werden Gefühle und Meinungen ausgedrückt; Textklassifikation: wie drückt sich Stil, Autorschaft, Textsorte, Thema etc. aus) besser gelöst wäre.</p>
            <p>Überall wo Sprachgebrauch quantitativ und maschinell analysiert wird, gibt es einen starken Trend, möglichst ohne linguistischen Kategorien und Theorien auszukommen und Black-Box-Systeme zu verwenden. Das ist nachvollziehbar, da es in den meisten Fällen darum geht, ein System zu bauen, das eine klar definierte Aufgabe sehr gut lösen kann. Obwohl diese Ansätze natürlich auch für die Korpuslinguistik interessant sind, genügen sie linguistischen Forschungsinteressen eigentlich nicht, da sie keinen Beitrag dazu leisten, sprachliche Phänomene zu verstehen und erklären zu können.</p>
            <p>Viel dramatischer ist jedoch, dass die Linguistik offensichtlich nicht in der Lage ist, einen nützlichen Beitrag zur Lösung der Probleme der maschinellen Textanalyse zu leisten. Die Linguistik scheint für die quantitative Analyse von Text weitgehend bedeutungslos zu werden.</p>
            <p>Um der Bedeutungslosigkeit zu entgehen, muss die Linguistik ein kritisches Verhältnis zur Forschungslogik in den ingenieurstechnischen Disziplinen pflegen und auf zwei Prinzipien bestehen: 1) Mehr linguistische Theorie. 2) Ergebnisse von quantitativen Analysen müssen gedeutet werden.</p>
            <p>Zu 1): Nicht nur für die Linguistik, sondern für alle geistes- und sozialwissenschaftlichen Disziplinen gilt: Eine theoretische Fundierung der Analysekategorien ist essentiell. Dafür werden valide Analysekategorien benötigt, die deutbar sind. Dieses Prinzip richtet sich jedoch keinesfalls gegen datengeleitete Verfahren, im Gegenteil: Sie sind es, die die theoretischen Modelle herausfordern und schärfen können. Aber das Ziel aller Analysen muss darin liegen, ein Puzzleteil zu einem besseren Verständnis sprachlicher Strukturen, von Sprachgebrauch oder gesellschaftlichen und kulturellen Bedeutungen von Sprache zu führen. Wir benötigen White-Box-, nicht Black-Box-Systeme.</p>
            <p>Das Problem der fehlenden Validität zeigt sich z.B. im Feld der sog. „Authorship Attribution“, also der Zuordnung eines Textes X zu einem Autor A, B, C, …. Um dies zu tun, stehen Texte zur Verfügung, von denen die Autorschaft bekannt ist. Die Frage ist dann also, ob über die sprachlichen Merkmale des Textes X automatisch bestimmt werden kann, wer der Autor/die Autorin (aus der Menge der möglichen Autoren/innen) von Text X ist. Genauer lautet die Frage aber, ob und wie sich persönlicher Schreibstil sprachlich niederschlägt.</p>
            <p>Besonders erfolgreich für diese Aufgabe sind Methoden maschinellen Lernens, die das Problem als Klassifikationsaufgabe auffassen und anhand von Trainingskorpora typische sprachliche Merkmale der Texte der jeweiligen Autor/innen lernen. Dabei zeigt sich, dass „low-level features like character n-grams are very successful for representing texts for stylistic purposes” (Stamatatos, 2009, S. 24). 
                <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {"citationID":"sxfqPHnj","properties":{"formattedCitation":"(Stamatatos, 2009, S. 24)","plainCitation":"(Stamatatos, 2009, S. 24)"},"citationItems":[{"id":9112,"uris":["http://zotero.org/users/677080/items/BIH6LCQ6"],"uri":["http://zotero.org/users/677080/items/BIH6LCQ6"],"itemData":{"id":9112,"type":"article-journal","title":"A Survey of Modern Authorship Attribution Methods","container-title":"J. Am. Soc. Inf. Sci. Technol.","page":"538–556","volume":"60","issue":"3","source":"ACM Digital Library","abstract":"Authorship attribution supported by statistical or computational methods has a long history starting from the 19th century and is marked by the seminal study of Mosteller and Wallace (1964) on the authorship of the disputed “Federalist Papers.” During the last decade, this scientific field has been developed substantially, taking advantage of research advances in areas such as machine learning, information retrieval, and natural language processing. The plethora of available electronic texts (e.g., e-mail messages, online forum messages, blogs, source code, etc.) indicates a wide variety of applications of this technology, provided it is able to handle short and noisy text from multiple candidate authors. In this article, a survey of recent advances of the automated approaches to attributing authorship is presented, examining their characteristics for both text representation and text classification. The focus of this survey is on computational requirements and settings rather than on linguistic or literary issues. We also discuss evaluation methodologies and criteria for authorship attribution studies and list open questions that will attract future work in this area. © 2009 Wiley Periodicals, Inc.","DOI":"10.1002/asi.v60:3","ISSN":"1532-2882","author":[{"family":"Stamatatos","given":"Efstathios"}],"issued":{"date-parts":[["2009",3]]}},"locator":"24"}],"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"} ?>
                Das bedeutet, solche Modelle, die auf der Distribution von Buchstaben-N-Grammen beruhen, sind, gemessen an einem Goldstandard, am erfolgreichsten. Allein: Solche Modelle lassen sich nicht linguistisch deuten, da völlig unklar ist, was sie eigentlich messen. Ist es Stil, Thema, Textsorte, …? Es handelt sich also weder um eine valide, noch um eine deutbare Kategorie (insbesondere, wenn das statistische Modell nicht einsehbar ist). Für spezifische Aufgaben der Autorschaftsattribution mag das ausreichend sein, aber bereits für forensische Anwendungen, beispielsweise vor Gericht, ist eine solche Modellierung fragwürdig und gefährlich. Und für eine linguistische Deutung des Phänomens Autorschaftsstil ist sie gänzlich unbrauchbar.<ref target="ftn2" n="2"/>
            </p>
            <p>Die Kritik geht jedoch nicht nur in Richtung des Textminings und der Computerlinguistik, manchmal nicht-valide Kategorien einzusetzen (was zudem oft für die dortigen Zwecke auch sinnvoll ist), sondern auch in die Richtung der Linguistik: Die Computer- und die Korpuslinguistik zeigen beide gleichermaßen, wie wichtig es ist, auch abstrakte Kategorien so zu definieren versuchen, dass überhaupt eine Chance besteht, sie für eine quantitative Analyse operationalisierbar zu machen. Wenn eine linguistische Kategorie so vage ist, dass sich selbst (geschulte) Menschen uneinig darüber sind, wenn sie an authentischem Sprachegebrauch angewendet werden, scheitert die quantitativ-maschinelle Lösung unweigerlich.</p>
            <p>2) Die Ergebnisse von quantitativen Analysen sind nicht Antworten auf Fragestellungen, sondern neue Daten, die vor einem geistes- und sozialwissenschaftlichen Hintergrund genauso hermeneutisch gedeutet werden müssen, wie einzelne Texte. Das ist vielleicht das größte Missverständnis, wenn Textminer und Computerlinguistinnen mit Korpuslinguistinnen zusammenarbeiten: Erstere wollen, dass ein Werkzeug ein Ergebnis hervorbringt, das an einem Goldstandard evaluiert werden kann. Das Ergebnis ist dann im Einzelfall richtig oder falsch und in der Gesamtheit genügend präzise oder nicht. Das Ergebnis ist dann auch im Idealfall die Lösung der Forschungsfrage. Bei den meisten geistes- und sozialwissenschaftlichen Fragestellungen beginnt auf der Grundlage dieser Ergebnisse jedoch ein Interpretationsprozess, um (meist in Kombination mit weiteren Analysen) eine plausible Deutung zu ermöglichen – eine vorläufige Deutung. Die Stärke der Geistes- und Sozialwissenschaften liegt dabei ja gerade darin, dass in ihrer Methodologie ein Zweifeln inhärent ist, mit dem die „gegenwärtig besiegelten Bedeutungen jeweils eingeklammert oder angezweifelt [werden], um zu prüfen, inwiefern sich nach rationalem Ermessen nicht bessere Lösungen, überlegenere Interpretationen oder zustimmungsfähigere Regelungen finden lassen“ (Honneth, 2016, S. 312). 
                <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {"citationID":"a207f3j33jm","properties":{"formattedCitation":"(Honneth, 2016, S. 312)","plainCitation":"(Honneth, 2016, S. 312)"},"citationItems":[{"id":9111,"uris":["http://zotero.org/users/677080/items/7IB9RNLN"],"uri":["http://zotero.org/users/677080/items/7IB9RNLN"],"itemData":{"id":9111,"type":"chapter","title":"Denaturierung der Lebenswelt. Vom dreifachen Nutzen der Geisteswissenschaften","container-title":"Texte zur Theorie der Geisteswissenschaften","collection-title":"Reclams Universal-Bibliothek","collection-number":"Nr. 19353","publisher":"Reclam","publisher-place":"Stuttgart","page":"283-315","source":"Gemeinsamer Bibliotheksverbund ISBN","event-place":"Stuttgart","ISBN":"978-3-15-019353-2","note":"OCLC: 932667571","language":"ger","editor":[{"family":"Panteos","given":"Athena"},{"family":"Rojek","given":"Tim"}],"author":[{"family":"Honneth","given":"Axel"}],"issued":{"date-parts":[["2016"]]}},"locator":"312"}],"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"} ?>
            </p>
            <p>Neben der Suche nach validen Analysekategorien und dem Hochhalten geisteswissenschaftlicher Prinzipien der Deutung sehe ich einen weiteren Aspekt, der helfen sollte, der Korpuslinguistik eine deutliche linguistische Prägung zu verleihen. Es ist der Versuch, korpuslinguistisches Arbeiten als „diagrammatisches Operieren“ aufzufassen. Mit dem Diagramm-Begriff folge ich Krämer (2016), 
                <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {"citationID":"a1t1dntdfrn","properties":{"formattedCitation":"(2016)","plainCitation":"(2016)"},"citationItems":[{"id":8547,"uris":["http://zotero.org/users/677080/items/BSGQZFK3"],"uri":["http://zotero.org/users/677080/items/BSGQZFK3"],"itemData":{"id":8547,"type":"book","title":"Figuration, Anschauung, Erkenntnis: Grundlinien einer Diagrammatologie","publisher":"Suhrkamp Verlag","number-of-pages":"373","source":"Google Books","abstract":"In unserer dreidimensionalen Welt sind wir umgeben von bebilderten und beschrifteten Flächen. Welche Rolle spielt die »Kulturtechnik der Verflachung« in unseren Wissenspraktiken? Worin besteht die kognitive Kreativität von Tabellen, Texten, Diagrammen und Karten, die für Erkenntnis und Wissenschaft unverzichtbar sind? Sybille Krämer untersucht, wie synoptische Anordnungen zu Denkzeugen werden. Sie analysiert die Erkenntniskraft der Linie als Wurzel eines diagrammatischen Denkens, dessen Spuren sich schon in den Erkenntnistheorien von Platon, Descartes, Kant und Wittgenstein sichern lassen. So entstehen die Konturen einer Diagrammatologie, in deren Rahmen sich die Orientierungsleistung und Imaginationskraft sichtbarer, räumlicher Schemata für das Erkennen erforschen lassen.","ISBN":"978-3-518-74467-3","note":"00000 \nGoogle-Books-ID: E8BlDQAAQBAJ","shortTitle":"Figuration, Anschauung, Erkenntnis","language":"de","author":[{"family":"Krämer","given":"Sybille"}],"issued":{"date-parts":[["2016",11,14]]}},"suppress-author":true}],"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"} ?>
                die deutlich macht, dass Diagramme als Formen der Visualisierung von Daten „Denkzeuge“ sind, mit denen operiert wird: Ich kann Daten in einem Diagramm darstellen (auf einer Karte, in einem Netzwerkgraph, einem Punkteplot, …) und danach damit operieren, um neue Erkenntnisse daraus zu ziehen. Wenn man einem breiten Diagramm-Begriff folgt, wird deutlich, dass auch Listen, Tabellen und dergleichen diagrammatischen Charakter haben (Siegel, 2009; Steinseifer, 2013). 
                <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {"citationID":"a2m4kclvdp1","properties":{"formattedCitation":"(Siegel, 2009; Steinseifer, 2013)","plainCitation":"(Siegel, 2009; Steinseifer, 2013)"},"citationItems":[{"id":7029,"uris":["http://zotero.org/users/677080/items/E99KT85J"],"uri":["http://zotero.org/users/677080/items/E99KT85J"],"itemData":{"id":7029,"type":"book","title":"Tabula: Figuren der Ordnung um 1600","publisher":"Akademie-Verlag","publisher-place":"Berlin / Boston","source":"Open WorldCat","event-place":"Berlin / Boston","URL":"http://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=711178","ISBN":"978-3-05-006222-8","shortTitle":"Tabula","language":"German","author":[{"family":"Siegel","given":"Steffen"}],"issued":{"date-parts":[["2009"]]},"accessed":{"date-parts":[["2015",4,1]]}}},{"id":6261,"uris":["http://zotero.org/users/677080/items/EF232UIW"],"uri":["http://zotero.org/users/677080/items/EF232UIW"],"itemData":{"id":6261,"type":"article-journal","title":"Texte sehen – Diagrammatologische Impulse für die Textlinguistik","container-title":"Zeitschrift für germanistische Linguistik","page":"8-39","volume":"41","issue":"1","source":"www.degruyter.com","abstract":"AbstractDiagrams are used to make complex relationships and proportions visually clear. Their underlying semiotic structure and their potential to generate an understanding of the complex phenomena they are referring to turn diagrams into distinctive media of representation and are the focus of a current debate in philosophy and cultural theory. Under the heading of ‘diagrammatics’ (Diagrammatik) or ‘diagrammatology’ (Diagrammatologie), the schematic iconicity (abstractivity) and the operational character (operativity) of diagrammatic reasoning – both central insights in Charles Sanders Peirce’s semiotic philosophy – are promoted in the debate as key concepts for cultural analysis.The paper outlines the discussion and draws on these two central concepts to argue that visual shape is a constitutive dimension of textuality. Written texts, even purely ‘verbal’ ones, are not only designed to be read, but can always be interpreted – or ‘seen’ – in terms of spatial relationships on a page: the shapes of lines and paragraphs often suffice to identify the genre of a text before a single word is read. But serving on their own as contextualisation cues is merely a side effect of the functions that the visual relationships of verbal parts have within a text: these relationships primarily allow for a flexible form of coherence and help readers navigate their way through complex texts. The paper shows how a diagrammatically informed pragmatic analysis can account for these functions, which have rarely been addressed within the linguistics of written discourse so far and are largely overlooked by both recent typographic and multimodal approaches alike. The paper concludes by outlining three key areas for future research: (1) the relationships between verbal and visual units on the page (or the screen), (2) the pragmatics of lists and tables as prototypes of diagrammatically structured text-parts; and (3) the diagrammatic character of epistemic writing.","author":[{"family":"Steinseifer","given":"Martin"}],"issued":{"date-parts":[["2013"]]}}}],"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"} ?>
                Dies sind nun aber Formen, die in der Korpuslinguistik zentral sind: Die Keyword in Context-Liste (zurückgehend etwa auf Zettelkästen im 16. Jahrhundert) etwa kann als Keimzelle eines völlig neuen Textverständnisses angesehen werden, mit dem die Einheit des Textes zerstört wird, um eine neue Sicht auf Textdaten zu gewinnen. Viele weitere Formen der Anordnung von Textdaten spielen ebenfalls wichtige Rollen, entscheidend etwa die Überführung von Textdaten in den Vektorraum, in dem operiert werden kann (z.B. in Form geometrischer Operationen – Lagen von Vektoren und ihren Winkeln zueinander). Aber auch die Erfindung der Partiturdarstellung bei Gesprächstrankripten, mit der überhaupt erst eine moderne Gesprächslinguistik möglich wurde, zeigt die Kraft von diagrammatischen Umformungen, um Daten neu lesbar zu machen. Hinter diesen diagrammatischen Umformungen stecken diagrammatische Grundfiguren (Bubenhofer im Druck b), die in den Geisteswissenschaften generell wirkmächtig sind.
            </p>
            <p>Ich meine, es lohnt sich, korpuslinguistisches Arbeiten unter diagrammatischer Perspektive zu reflektieren, um die Mechanismen und Möglichkeiten der Gegenstandskonstitution besser zu verstehen. Die Digitalität der Daten und Methoden erlaubt dabei neue Transformationen und macht Daten, egal welcher Modalität, miteinander verrechenbar. Aber die diagrammatischen Grundfiguren führen zu unterschiedlichen Gegenständen: Repräsentiert in einem Vektorraum geben die gleichen Daten einen völlig anderen Gegenstand ab als dargestellt in einer Keyword in Context-Liste. Und es müsste vordringliches Ziel sein, noch ganz andere Formen der diagrammatischen Darstellung von Text zu finden, um damit andere Gegenstandskonstitutionen und Fragestellungen zu ermöglichen. Die algorithmische Repräsentation der Daten folgt dabei ebenfalls den diagrammatischen Transformationen (Beispiel Vektorraum) und kann daher nicht unabhängig davon gedacht werden. Für eine hermeneutische Deutung brauchbare Analysekategorien zu erarbeiten, bedeutet deshalb auch, die damit verbundenen diagrammatischen Operationen zu reflektieren. Dafür nötig sind semiotische und natürlich auch wissenschaftstheoretische Überlegungen, die für alle Disziplinen, die mit maschineller Textanalyse befasst sind, relevant sein müssten.</p>
        </body>
        <back>
         <div type="notes">
            <note xml:id="ftn1" n="1" rend="footnote text"> Dieses „extended Abstract“ ist eine verkürzte und angepasste Fassung des stärker linguistisch ausgerichteten Beitrages von Bubenhofer (im Druck a).</note>
            <note xml:id="ftn2" n="2" rend="footnote text"> Vgl. für eine aktuelle linguistisch motivierte Diskussion von stilometrischen Messmethoden für die Autorschaftsattribution Büttner et al. (2017). </note>
         </div>
         <div type="bibliogr">
                <listBibl>
                    <head>Bibliographie</head>
                    <bibl><hi rend="bold">Bubenhofer, Noah </hi>(im Druck a): Wenn „Linguistik“ in „Korpuslinguistik“ bedeutungslos wird. Vier Thesen zur Zukunft der Korpuslinguistik. In: Osnabrücker Beiträge zur Sprachtheorie (OBST).</bibl>
                    <bibl><hi rend="bold">Bubenhofer, Noah </hi>(im Druck b): Visual Linguistics: Plädoyer für ein neues Forschungsfeld. In: Bubenhofer, Noah / Kupietz, Marc (Hg.): Visualisierung sprachlicher Daten. Heidelberg: HeiUP.</bibl>
                    <bibl><hi rend="bold">Büttner, Andreas / Dimpel, Friedrich Michael / Evert, Stefan / Jannidis, Fotis / Pielström, Steffen / Proisl, Thomas / Reger, Isabella / Schöch, Christof / Vitt, Thorsten </hi>(2017): »Delta« in der stilometrischen Autorschaftsattribution. In: Zeitschrift für digitale Geisteswissenschaften. text/html Format. DOI: 10.17175/2017_006.</bibl>
                    <bibl><hi rend="bold">Honneth, Axel </hi>(2016): Denaturierung der Lebenswelt. Vom dreifachen Nutzen der Geisteswissenschaften. In: Panteos, A./Rojek, T. (Hrsg.): 
                        <hi rend="italic">Texte zur Theorie der Geisteswissenschaften</hi>, 
                        <hi rend="italic">Reclams Universal-Bibliothek</hi>. Stuttgart : Reclam, S. 283–315
                    </bibl>
                    <bibl><hi rend="bold">Krämer, Sybille </hi>(2016): 
                        <hi rend="italic">Figuration, Anschauung, Erkenntnis: Grundlinien einer Diagrammatologie.</hi> Frankfurt/Main: Suhrkamp Verlag.
                    </bibl>
                    <bibl><hi rend="bold">Nakov, Preslav/Ritter, Alan/Rosenthal, Sara/Stoyanov, Veselin/Sebastiani, Fabrizio </hi>(2016): SemEval-2016 Task 4: Sentiment Analysis in Twitter. In: 
                        <hi rend="italic">Proceedings of the 10th International Workshop on Semantic Evaluation</hi>, 
                        <hi rend="italic">SemEval ’16</hi>. San Diego, California : Association for Computational Linguistics.
                    </bibl>
                    <bibl><hi rend="bold">Siegel, Steffen </hi>(2009): 
                        <hi rend="italic">Tabula: Figuren der Ordnung um 1600</hi>. Berlin / Boston : Akademie-Verlag.
                    </bibl>
                    <bibl><hi rend="bold">Stamatatos, Efstathios </hi>(2009): A Survey of Modern Authorship Attribution Methods. In: 
                        <hi rend="italic">J. Am. Soc. Inf. Sci. Technol.</hi> Bd. 60, Nr. 3, S. 538–556
                    </bibl>
                    <bibl><hi rend="bold">Steinseifer, Martin </hi>(2013): Texte sehen – Diagrammatologische Impulse für die Textlinguistik. In: 
                        <hi rend="italic">Zeitschrift für germanistische Linguistik</hi> Bd. 41, Nr. 1, S. 8–39
                    </bibl>
                </listBibl>
            </div>
      </back>
    </text>
</TEI>
